{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbe6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0baedc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Dict\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from utils import datasets, metrics\n",
    "from utils.ensembles import EnsembleCPDModel\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcc28c",
   "metadata": {},
   "source": [
    "# Fixed evaluation pipeline\n",
    "(use pre-computed out banks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics_on_set(\n",
    "    test_out_bank: List[torch.Tensor],\n",
    "    test_uncertainties_bank: List[torch.Tensor],\n",
    "    test_labels_bank: List[torch.Tensor],\n",
    "    threshold: float = 0.5,\n",
    "    verbose: bool = True,\n",
    "    device: str = \"cuda\",\n",
    "    uncert_th: float = None,\n",
    "    margin_list: List[int] = None,\n",
    ") -> Tuple[int, int, int, int, float, float]:\n",
    "\n",
    "    FP_delays = []\n",
    "    delays = []\n",
    "    covers = []\n",
    "    TN, FP, FN, TP = (0, 0, 0, 0)\n",
    "\n",
    "    TN_margin_dict, FP_margin_dict, FN_margin_dict, TP_margin_dict = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "    if margin_list is not None:\n",
    "        TN_margin_dict, FP_margin_dict, FN_margin_dict, TP_margin_dict = (\n",
    "            {},\n",
    "            {},\n",
    "            {},\n",
    "            {},\n",
    "        )\n",
    "        for margin in margin_list:\n",
    "            TN_margin_dict[margin] = 0\n",
    "            FP_margin_dict[margin] = 0\n",
    "            FN_margin_dict[margin] = 0\n",
    "            TP_margin_dict[margin] = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_out, test_uncertainties, test_labels in zip(\n",
    "            test_out_bank, test_uncertainties_bank, test_labels_bank\n",
    "        ):\n",
    "            if test_uncertainties is not None and uncert_th is not None:\n",
    "                cropped_outs = (test_out > threshold) & (test_uncertainties < uncert_th)\n",
    "\n",
    "            else:\n",
    "                cropped_outs = test_out > threshold\n",
    "\n",
    "            (\n",
    "                (tn, fp, fn, tp, FP_delay, delay, cover),\n",
    "                (tn_margin_dict, fp_margin_dict, fn_margin_dict, tp_margin_dict),\n",
    "            ) = metrics.calculate_metrics(test_labels, cropped_outs, margin_list)\n",
    "\n",
    "            TN += tn\n",
    "            FP += fp\n",
    "            FN += fn\n",
    "            TP += tp\n",
    "\n",
    "            if margin_list is not None:\n",
    "                for margin in margin_list:\n",
    "                    TN_margin_dict[margin] += tn_margin_dict[margin]\n",
    "                    FP_margin_dict[margin] += fp_margin_dict[margin]\n",
    "                    FN_margin_dict[margin] += fn_margin_dict[margin]\n",
    "                    TP_margin_dict[margin] += tp_margin_dict[margin]\n",
    "\n",
    "            FP_delays.append(FP_delay.detach().cpu())\n",
    "            delays.append(delay.detach().cpu())\n",
    "            covers.extend(cover)\n",
    "\n",
    "    mean_FP_delay = torch.cat(FP_delays).float().mean().item()\n",
    "    mean_delay = torch.cat(delays).float().mean().item()\n",
    "    mean_cover = np.mean(covers)\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"TN: {}, FP: {}, FN: {}, TP: {}, DELAY:{}, FP_DELAY:{}, COVER: {}\".format(\n",
    "                TN, FP, FN, TP, mean_delay, mean_FP_delay, mean_cover\n",
    "            )\n",
    "        )\n",
    "\n",
    "    del FP_delays, delays, covers\n",
    "    gc.collect()\n",
    "    if \"cuda\" in device:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return (\n",
    "        (TN, FP, FN, TP, mean_delay, mean_FP_delay, mean_cover),\n",
    "        (TN_margin_dict, FP_margin_dict, FN_margin_dict, TP_margin_dict),\n",
    "    )\n",
    "\n",
    "def evaluation_pipeline(     \n",
    "    test_out_bank: List[torch.Tensor],\n",
    "    test_uncertainties_bank: List[torch.Tensor],\n",
    "    test_labels_bank: List[torch.Tensor],\n",
    "     \n",
    "    threshold_list: List[float],\n",
    "    device: str = \"cuda\",\n",
    "    verbose: bool = False,\n",
    "    model_type: str = \"seq2seq\",\n",
    "    subseq_len: int = None,\n",
    "    scale: int = None,\n",
    "    uncert_th: float = None,\n",
    "    q: float = None,\n",
    "    margin_list: List[int] = None,\n",
    "    step: int = 1,\n",
    "    alpha: float = 1.0,\n",
    ") -> Tuple[Tuple[float], dict, dict]:\n",
    "\n",
    "    cover_dict = {}\n",
    "    f1_dict = {}\n",
    "\n",
    "    if margin_list is not None:\n",
    "        final_f1_margin_dict = {}\n",
    "\n",
    "    delay_dict = {}\n",
    "    fp_delay_dict = {}\n",
    "    confusion_matrix_dict = {}\n",
    "\n",
    "    if model_type == \"cusum_aggr\":\n",
    "        threshold_list = [0.5]\n",
    "        if verbose and len(threshold_list) > 1:\n",
    "            print(\"No need in threshold list for CUSUM. Take threshold = 0.5.\")\n",
    "\n",
    "    for threshold in tqdm(threshold_list):\n",
    "        final_f1_margin_dict[threshold] = {}\n",
    "\n",
    "        (\n",
    "            (TN, FP, FN, TP, mean_delay, mean_fp_delay, cover),\n",
    "            (TN_margin_dict, FP_margin_dict, FN_margin_dict, TP_margin_dict),\n",
    "        ) = evaluate_metrics_on_set(\n",
    "            test_out_bank=test_out_bank,\n",
    "            test_uncertainties_bank=test_uncertainties_bank,\n",
    "            test_labels_bank=test_labels_bank,\n",
    "            threshold=threshold,\n",
    "            verbose=False,\n",
    "            device=device,\n",
    "            uncert_th=uncert_th,\n",
    "            margin_list=margin_list,\n",
    "        )\n",
    "\n",
    "        confusion_matrix_dict[threshold] = (TN, FP, FN, TP)\n",
    "        delay_dict[threshold] = mean_delay\n",
    "        fp_delay_dict[threshold] = mean_fp_delay\n",
    "\n",
    "        cover_dict[threshold] = cover\n",
    "        f1_dict[threshold] = metrics.F1_score((TN, FP, FN, TP))\n",
    "\n",
    "        if margin_list is not None:\n",
    "            f1_margin_dict = {}\n",
    "            for margin in margin_list:\n",
    "                (TN_margin, FP_margin, FN_margin, TP_margin) = (\n",
    "                    TN_margin_dict[margin],\n",
    "                    FP_margin_dict[margin],\n",
    "                    FN_margin_dict[margin],\n",
    "                    TP_margin_dict[margin],\n",
    "                )\n",
    "                f1_margin_dict[margin] = metrics.F1_score(\n",
    "                    (TN_margin, FP_margin, FN_margin, TP_margin)\n",
    "                )\n",
    "            final_f1_margin_dict[threshold] = f1_margin_dict\n",
    "\n",
    "    # fix dict structure\n",
    "    if margin_list is not None:\n",
    "        final_f1_margin_dict_fixed = {}\n",
    "        for margin in margin_list:\n",
    "            f1_scores_for_margin_dict = {}\n",
    "            for threshold in threshold_list:\n",
    "                f1_scores_for_margin_dict[threshold] = final_f1_margin_dict[threshold][\n",
    "                    margin\n",
    "                ]\n",
    "            final_f1_margin_dict_fixed[margin] = f1_scores_for_margin_dict\n",
    "\n",
    "    if model_type == \"cusum_aggr\":\n",
    "        auc = None\n",
    "    else:\n",
    "        auc = metrics.area_under_graph(list(delay_dict.values()), list(fp_delay_dict.values()))\n",
    "\n",
    "    # Conf matrix and F1\n",
    "    best_th_f1 = max(f1_dict, key=f1_dict.get)\n",
    "\n",
    "    best_conf_matrix = (\n",
    "        confusion_matrix_dict[best_th_f1][0],\n",
    "        confusion_matrix_dict[best_th_f1][1],\n",
    "        confusion_matrix_dict[best_th_f1][2],\n",
    "        confusion_matrix_dict[best_th_f1][3],\n",
    "    )\n",
    "    best_f1 = f1_dict[best_th_f1]\n",
    "\n",
    "    # Cover\n",
    "    best_cover = cover_dict[best_th_f1]\n",
    "\n",
    "    best_th_cover = max(cover_dict, key=cover_dict.get)\n",
    "    max_cover = cover_dict[best_th_cover]\n",
    "\n",
    "    if margin_list is not None:\n",
    "        max_f1_margins_dict = {}\n",
    "        max_th_f1_margins_dict = {}\n",
    "        for margin in margin_list:\n",
    "            curr_max_th_f1_margin = max(\n",
    "                final_f1_margin_dict_fixed[margin],\n",
    "                key=final_f1_margin_dict_fixed[margin].get,\n",
    "            )\n",
    "            max_th_f1_margins_dict[margin] = curr_max_th_f1_margin\n",
    "            max_f1_margins_dict[margin] = final_f1_margin_dict_fixed[margin][\n",
    "                curr_max_th_f1_margin\n",
    "            ]\n",
    "    else:\n",
    "        max_f1_margins_dict, max_th_f1_margins_dict = None, None\n",
    "\n",
    "    # Time to FA, detection delay\n",
    "    best_time_to_FA = fp_delay_dict[best_th_f1]\n",
    "    best_delay = delay_dict[best_th_f1]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"AUC:\", round(auc, 4) if auc is not None else auc)\n",
    "        print(\n",
    "            \"Time to FA {}, delay detection {} for best-F1 threshold: {}\".format(\n",
    "                round(best_time_to_FA, 4), round(best_delay, 4), round(best_th_f1, 4)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"TN {}, FP {}, FN {}, TP {} for best-F1 threshold: {}\".format(\n",
    "                best_conf_matrix[0],\n",
    "                best_conf_matrix[1],\n",
    "                best_conf_matrix[2],\n",
    "                best_conf_matrix[3],\n",
    "                round(best_th_f1, 4),\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Max F1 {}: for best-F1 threshold {}\".format(\n",
    "                round(best_f1, 4), round(best_th_f1, 4)\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"COVER {}: for best-F1 threshold {}\".format(\n",
    "                round(best_cover, 4), round(best_th_f1, 4)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"Max COVER {}: for threshold {}\".format(\n",
    "                round(cover_dict[max(cover_dict, key=cover_dict.get)], 4),\n",
    "                round(max(cover_dict, key=cover_dict.get), 4),\n",
    "            )\n",
    "        )\n",
    "        if margin_list is not None:\n",
    "            for margin in margin_list:\n",
    "                print(\n",
    "                    \"Max F1 with margin {}: {} for best threshold {}\".format(\n",
    "                        margin,\n",
    "                        round(max_f1_margins_dict[margin], 4),\n",
    "                        round(max_th_f1_margins_dict[margin], 4),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return (\n",
    "        (\n",
    "            best_th_f1,\n",
    "            best_time_to_FA,\n",
    "            best_delay,\n",
    "            auc,\n",
    "            best_conf_matrix,\n",
    "            best_f1,\n",
    "            best_cover,\n",
    "            best_th_cover,\n",
    "            max_cover,\n",
    "        ),\n",
    "        (max_th_f1_margins_dict, max_f1_margins_dict),\n",
    "        delay_dict,\n",
    "        fp_delay_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf07162",
   "metadata": {},
   "source": [
    "# Model with LogReg / XGBoost head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d6843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredHeadModel():\n",
    "    def __init__(\n",
    "        self, \n",
    "        ens_model,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        head_type=\"logreg\",\n",
    "        num_models=10,\n",
    "        hidden_size=26,\n",
    "    ):\n",
    "        assert head_type in [\"logreg\", \"xgboost\", \"mlp\"], \"Unknown head type\"\n",
    "        \n",
    "        self.model = ens_model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        \n",
    "        self.loss = None\n",
    "        \n",
    "        if head_type == \"logreg\":\n",
    "            self.head = LogisticRegression()\n",
    "        else:\n",
    "            self.head = XGBClassifier()\n",
    "        \n",
    "        self.train_ens_out = None\n",
    "        self.train_labels = None\n",
    "        self.head_fitted = False\n",
    "        \n",
    "    def get_train_embeddings(self):\n",
    "        ens_out_bank, labels_bank = [], []\n",
    "        for batch, labels in tqdm(self.train_dataloader):\n",
    "            ens_preds = self.model.predict_all_models(batch)\n",
    "            ens_out_bank.append(ens_preds)\n",
    "            labels_bank.append(labels)\n",
    "            \n",
    "        train_ens_out = torch.cat(ens_out_bank, dim=1).permute(1, 2, 0).detach() # (dataset_size, seq_len, num_models)\n",
    "        train_labels = torch.cat(labels_bank, dim=0)\n",
    "        \n",
    "        self.train_ens_out = train_ens_out\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "        return train_ens_out, train_labels\n",
    "    \n",
    "    def fit_head(self, n_epochs=10, batch_size=64, accelarator=\"cpu\", lr=1e-3):\n",
    "        assert self.train_ens_out is not None, \"Need to get embeddings\"\n",
    "        assert self.train_labels is not None, \"Need to get labels\"\n",
    "        \n",
    "        seq_num, seq_len, model_num = self.train_ens_out.shape\n",
    "        train_ens_out = self.train_ens_out.reshape(-1, model_num)\n",
    "        train_labels = self.train_labels.reshape(seq_num * seq_len)\n",
    "\n",
    "        self.head.fit(train_ens_out, train_labels)              \n",
    "        self.head_fitted = True\n",
    "    \n",
    "    def get_test_predictions_banks(self):\n",
    "        assert self.head_fitted, \"Need to fit the head\"\n",
    "        \n",
    "        test_out_bank, test_out_head_bank, test_uncertainties_bank, test_labels_bank = [], [], [], []\n",
    "\n",
    "        for test_batch, test_labels in tqdm(self.test_dataloader):\n",
    "            preds_mean, preds_std = self.model.predict(test_batch)\n",
    "            ens_preds = self.model.preds.detach()\n",
    "\n",
    "            test_out_bank.append(preds_mean.detach())\n",
    "            test_uncertainties_bank.append(preds_std.detach())\n",
    "            test_labels_bank.append(test_labels)\n",
    "\n",
    "            ens_preds = ens_preds.permute(1, 2, 0) # -> (batch_size, seq_len, model_num)\n",
    "            preds_head_batch = []\n",
    "            for ens_preds_for_seq in ens_preds:\n",
    "                preds_head = self.head.predict(ens_preds_for_seq)\n",
    "                preds_head_batch.append(preds_head)\n",
    "\n",
    "            preds_head_batch = torch.from_numpy(np.stack(preds_head_batch))\n",
    "            test_out_head_bank.append(preds_head_batch)\n",
    "        \n",
    "        return test_out_bank, test_out_head_bank, test_uncertainties_bank, test_labels_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e91cd",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "## BCE for HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a73867bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"seq2seq\"\n",
    "\n",
    "experiments_name = \"human_activity\"\n",
    "\n",
    "path_to_config = \"configs/\" + experiments_name + \"_\" + model_type + \".yaml\"\n",
    "\n",
    "with open(path_to_config, 'r') as f:\n",
    "    args_config = yaml.safe_load(f.read())\n",
    "\n",
    "args_config[\"experiments_name\"] = experiments_name\n",
    "args_config[\"model_type\"] = model_type\n",
    "args_config[\"num_workers\"] = 4\n",
    "\n",
    "args_config[\"loss_type\"] = \"bce\"\n",
    "\n",
    "args_config[\"learning\"][\"accelerator\"] = 'cpu'\n",
    "args_config[\"learning\"][\"devices\"] = 1\n",
    "\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name).get_dataset_()\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=False)\n",
    "test_dataloader_shuffle = DataLoader(\n",
    "    test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c104fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_har_bce = EnsembleCPDModel(args_config, n_models=10)\n",
    "ens_har_bce.load_models_list(\n",
    "    f\"saved_models/{args_config['loss_type']}/{experiments_name}/full_sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9079822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_head_model = PredHeadModel(\n",
    "    ens_har_bce,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    head_type=\"logreg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bfb621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abec5ac340e4992861a04163e297100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35ee2b5a4b54998812ea75b10cbb216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = pred_head_model.get_train_embeddings()\n",
    "pred_head_model.fit_head()\n",
    "(\n",
    "    test_out_bank, test_out_head_bank, test_uncertainties_bank, test_labels_bank\n",
    ") = pred_head_model.get_test_predictions_banks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c00a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d61599ebe241448f5938dc73213150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 44.9517\n",
      "Time to FA 11.0666, delay detection 0.095 for best-F1 threshold: 0.6117\n",
      "TN 171, FP 7, FN 10, TP 1149 for best-F1 threshold: 0.6117\n",
      "Max F1 0.9927: for best-F1 threshold 0.6117\n",
      "COVER 0.9938: for best-F1 threshold 0.6117\n",
      "Max COVER 0.994: for threshold 0.5875\n",
      "Max F1 with margin 1: 0.9878 for best threshold 0.5875\n",
      "Max F1 with margin 2: 0.99 for best threshold 0.5875\n",
      "Max F1 with margin 4: 0.9922 for best threshold 0.5628\n",
      "Max F1 with margin 8: 0.9931 for best threshold 0.5628\n"
     ]
    }
   ],
   "source": [
    "threshold_number = 100\n",
    "threshold_list = np.linspace(-5, 5, threshold_number)\n",
    "threshold_list = 1 / (1 + np.exp(-threshold_list))\n",
    "threshold_list = [-0.001] + list(threshold_list) + [1.001]\n",
    "\n",
    "evaluation_pipeline(    \n",
    "    test_out_bank=test_out_bank,\n",
    "    test_uncertainties_bank=test_uncertainties_bank,\n",
    "    test_labels_bank=test_labels_bank,\n",
    "    threshold_list=threshold_list,\n",
    "    device=\"cpu\",\n",
    "    verbose=True,\n",
    "    model_type=\"seq2seq\",\n",
    "    margin_list=[1, 2, 4, 8]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc72b365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1480422d6ae4647b1a8bc2019444b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.0\n",
      "Time to FA 10.9327, delay detection 0.0464 for best-F1 threshold: 0.5\n",
      "TN 168, FP 26, FN 5, TP 1138 for best-F1 threshold: 0.5\n",
      "Max F1 0.9866: for best-F1 threshold 0.5\n",
      "COVER 0.9928: for best-F1 threshold 0.5\n",
      "Max COVER 0.9928: for threshold 0.5\n",
      "Max F1 with margin 1: 0.9866 for best threshold 0.5\n",
      "Max F1 with margin 2: 0.987 for best threshold 0.5\n",
      "Max F1 with margin 4: 0.9901 for best threshold 0.5\n",
      "Max F1 with margin 8: 0.9905 for best threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# head\n",
    "evaluation_pipeline(    \n",
    "    test_out_bank=test_out_head_bank,\n",
    "    test_uncertainties_bank=test_uncertainties_bank,\n",
    "    test_labels_bank=test_labels_bank,\n",
    "    threshold_list=[0.5],\n",
    "    device=\"cpu\",\n",
    "    verbose=True,\n",
    "    model_type=\"seq2seq\",\n",
    "    margin_list=[1, 2, 4, 8]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67a340",
   "metadata": {},
   "source": [
    "## TS-CP for HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d9a0ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"tscp\"\n",
    "\n",
    "experiments_name = \"human_activity\"\n",
    "\n",
    "path_to_config = \"configs/\" + experiments_name + \"_\" + model_type + \".yaml\"\n",
    "\n",
    "with open(path_to_config, 'r') as f:\n",
    "    args_config = yaml.safe_load(f.read())\n",
    "\n",
    "args_config[\"experiments_name\"] = experiments_name\n",
    "args_config[\"model_type\"] = model_type\n",
    "args_config[\"num_workers\"] = 4\n",
    "\n",
    "args_config[\"learning\"][\"accelerator\"] = 'cpu'\n",
    "args_config[\"learning\"][\"devices\"] = 1\n",
    "\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name).get_dataset_()\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=False)\n",
    "test_dataloader_shuffle = DataLoader(test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502d0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_har_tscp = EnsembleCPDModel(args_config, n_models=10)\n",
    "ens_har_tscp.load_models_list(\n",
    "    f\"saved_models/{model_type}/{experiments_name}/window_{args_config['model']['window']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca57ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_head_model = PredHeadModel(\n",
    "    ens_har_tscp,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    head_type=\"logreg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c94377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6348c0a984ca4b3699f7554db0a01cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m pred_head_model\u001b[38;5;241m.\u001b[39mget_train_embeddings()\n\u001b[1;32m      2\u001b[0m pred_head_model\u001b[38;5;241m.\u001b[39mfit_head()\n\u001b[1;32m      4\u001b[0m (\n\u001b[1;32m      5\u001b[0m     test_out_bank, test_out_head_bank, test_uncertainties_bank, test_labels_bank\n\u001b[1;32m      6\u001b[0m ) \u001b[38;5;241m=\u001b[39m pred_head_model\u001b[38;5;241m.\u001b[39mget_test_predictions_banks()\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mPredHeadModel.get_train_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m ens_out_bank, labels_bank \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader):\n\u001b[0;32m---> 31\u001b[0m     ens_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict_all_models(batch)\n\u001b[1;32m     32\u001b[0m     ens_out_bank\u001b[38;5;241m.\u001b[39mappend(ens_preds)\n\u001b[1;32m     33\u001b[0m     labels_bank\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/ensembles.py:168\u001b[0m, in \u001b[0;36mEnsembleCPDModel.predict_all_models\u001b[0;34m(self, inputs, scale, step, alpha)\u001b[0m\n\u001b[1;32m    160\u001b[0m     outs \u001b[38;5;241m=\u001b[39m klcpd\u001b[38;5;241m.\u001b[39mget_klcpd_output_scaled(\n\u001b[1;32m    161\u001b[0m         model, inputs, model\u001b[38;5;241m.\u001b[39mwindow_1, model\u001b[38;5;241m.\u001b[39mwindow_2, scale\u001b[38;5;241m=\u001b[39mscale\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtscp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# outs = tscp.get_tscp_output_scaled(model, inputs, model.window_1, model.window_2, scale=scale)\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# outs = tscp.get_tscp_output_scaled_padded(\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m#    model, inputs, model.window_1, model.window_2, scale=scale, step=step, alpha=alpha\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     outs \u001b[38;5;241m=\u001b[39m tscp\u001b[38;5;241m.\u001b[39mget_tscp_output_padded(\n\u001b[1;32m    169\u001b[0m         model, inputs, model\u001b[38;5;241m.\u001b[39mwindow_1, model\u001b[38;5;241m.\u001b[39mwindow_2, step\u001b[38;5;241m=\u001b[39mstep\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# outs = tscp.get_tscp_output(\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m#    model, inputs, model.window_1, model.window_2, step=step\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     outs \u001b[38;5;241m=\u001b[39m tscp\u001b[38;5;241m.\u001b[39mpost_process_tscp_output(outs, scale\u001b[38;5;241m=\u001b[39mscale, alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/tscp.py:265\u001b[0m, in \u001b[0;36mget_tscp_output_padded\u001b[0;34m(tscp_model, batch, window_1, window_2, step)\u001b[0m\n\u001b[1;32m    263\u001b[0m pred_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m history_slice, future_slice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_history_slices, batch_future_slices):\n\u001b[0;32m--> 265\u001b[0m     curr_history, curr_future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(tscp_model, [history_slice, future_slice])\n\u001b[1;32m    266\u001b[0m     rep_sim \u001b[38;5;241m=\u001b[39m _cosine_simililarity_dim1(curr_history, curr_future)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[1;32m    267\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# duplicate similarities in case of step > 1, crop the remainder\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/tscp.py:669\u001b[0m, in \u001b[0;36mTSCP_model.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do forward pass through the model.\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m:param inputs: input tensor\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m:return: output\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    668\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__preprocess(inputs)\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/tscp.py:587\u001b[0m, in \u001b[0;36mBaseTSCPEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    583\u001b[0m batch_size, seq_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    584\u001b[0m out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    585\u001b[0m     batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, seq_len\n\u001b[1;32m    586\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# shape is (batch_size, c_in, timesteps)\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcn_layer(out)\n\u001b[1;32m    588\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    589\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(out))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/tscp.py:528\u001b[0m, in \u001b[0;36mTCN.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    526\u001b[0m out \u001b[38;5;241m=\u001b[39m inp\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_blocks:\n\u001b[0;32m--> 528\u001b[0m     out, skip_out \u001b[38;5;241m=\u001b[39m layer(out)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_skip_connections:\n\u001b[1;32m    530\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m skip_out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/data/stepikin/InDiD/UE_for_CPD/code/utils/tscp.py:434\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# do causal padding\u001b[39;00m\n\u001b[1;32m    433\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(out, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m--> 434\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_2(out)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_batch_norm:\n\u001b[1;32m    436\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_2(out)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = pred_head_model.get_train_embeddings()\n",
    "pred_head_model.fit_head()\n",
    "\n",
    "(\n",
    "    test_out_bank, test_out_head_bank, test_uncertainties_bank, test_labels_bank\n",
    ") = pred_head_model.get_test_predictions_banks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e14ca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4181c2fe5a2d4882b66e05652c62519b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 48.0926\n",
      "Time to FA 10.279, delay detection 0.8841 for best-F1 threshold: 0.7428\n",
      "TN 156, FP 130, FN 76, TP 975 for best-F1 threshold: 0.7428\n",
      "Max F1 0.9045: for best-F1 threshold 0.7428\n",
      "COVER 0.9125: for best-F1 threshold 0.7428\n",
      "Max COVER 0.9383: for threshold 0.3646\n",
      "Max F1 with margin 1: 0.9304 for best threshold 0.3646\n",
      "Max F1 with margin 2: 0.9437 for best threshold 0.2384\n",
      "Max F1 with margin 4: 0.9489 for best threshold 0.2384\n",
      "Max F1 with margin 8: 0.9494 for best threshold 0.2384\n"
     ]
    }
   ],
   "source": [
    "threshold_number = 100\n",
    "threshold_list = np.linspace(-5, 5, threshold_number)\n",
    "threshold_list = 1 / (1 + np.exp(-threshold_list))\n",
    "threshold_list = [-0.001] + list(threshold_list) + [1.001]\n",
    "\n",
    "evaluation_pipeline(    \n",
    "    test_out_bank=test_out_bank,\n",
    "    test_uncertainties_bank=test_uncertainties_bank,\n",
    "    test_labels_bank=test_labels_bank,\n",
    "    threshold_list=threshold_list,\n",
    "    device=\"cpu\",\n",
    "    verbose=True,\n",
    "    model_type=\"seq2seq\",\n",
    "    margin_list=[1, 2, 4, 8]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "437945b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e682eda8eee4ba69f3115d5af1e70d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.0\n",
      "Time to FA 9.5744, delay detection 0.2468 for best-F1 threshold: 0.5\n",
      "TN 145, FP 289, FN 12, TP 891 for best-F1 threshold: 0.5\n",
      "Max F1 0.8555: for best-F1 threshold 0.5\n",
      "COVER 0.9382: for best-F1 threshold 0.5\n",
      "Max COVER 0.9382: for threshold 0.5\n",
      "Max F1 with margin 1: 0.9193 for best threshold 0.5\n",
      "Max F1 with margin 2: 0.9348 for best threshold 0.5\n",
      "Max F1 with margin 4: 0.9447 for best threshold 0.5\n",
      "Max F1 with margin 8: 0.947 for best threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "evaluation_pipeline(    \n",
    "    test_out_bank=test_out_head_bank,\n",
    "    test_uncertainties_bank=test_uncertainties_bank,\n",
    "    test_labels_bank=test_labels_bank,\n",
    "    threshold_list=[0.5],\n",
    "    device=\"cpu\",\n",
    "    verbose=True,\n",
    "    model_type=\"seq2seq\",\n",
    "    margin_list=[1, 2, 4, 8]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e7cee",
   "metadata": {},
   "source": [
    "## TS-CP for YAHOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5945f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464dfe2c",
   "metadata": {},
   "source": [
    "## BCE for Explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b697e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23184440",
   "metadata": {},
   "source": [
    "# MLP Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPHeadModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ens_model,\n",
    "        train_dl,\n",
    "        val_dl,\n",
    "        num_models=10,\n",
    "        hidden_size=16,\n",
    "        learning_rate: float = 1e-3,\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = ens_model\n",
    "\n",
    "        # freeze backbone model\n",
    "        for m in self.model.models_list:\n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(num_models, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        # BCE loss for seq2seq binary classification\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        ens_preds = self.model.predict_all_models(inputs)\n",
    "        ens_preds = ens_preds.permute(1, 2, 0)\n",
    "        out = self.head(ens_preds)\n",
    "            \n",
    "        return out.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> Dict[str, float]:\n",
    "        inputs, labels = batch\n",
    "        preds = self.forward(inputs)\n",
    "        loss = self.loss(preds, labels.float())\n",
    "        \n",
    "        acc = ((preds > 0.5).long() == labels).float().mean()\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        return {\"preds\": preds, \"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> Dict[str, float]:\n",
    "        inputs, labels = batch\n",
    "        preds = self.forward(inputs)\n",
    "        loss = self.loss(preds, labels.float())\n",
    "        \n",
    "        acc = ((preds > 0.5).long() == labels).float().mean()\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True)\n",
    "        \n",
    "        return {\"preds\": preds, \"loss\": loss, \"acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        \"\"\"Initialize optimizer for the LocalValidationModel.\"\"\"\n",
    "        opt = torch.optim.Adam(self.head.parameters(), lr=self.lr)\n",
    "        return opt\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bb41420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"seq2seq\"\n",
    "\n",
    "experiments_name = \"human_activity\"\n",
    "\n",
    "path_to_config = \"configs/\" + experiments_name + \"_\" + model_type + \".yaml\"\n",
    "\n",
    "with open(path_to_config, 'r') as f:\n",
    "    args_config = yaml.safe_load(f.read())\n",
    "\n",
    "args_config[\"experiments_name\"] = experiments_name\n",
    "args_config[\"model_type\"] = model_type\n",
    "args_config[\"num_workers\"] = 4\n",
    "\n",
    "args_config[\"loss_type\"] = \"bce\"\n",
    "\n",
    "args_config[\"learning\"][\"accelerator\"] = 'cpu'\n",
    "args_config[\"learning\"][\"devices\"] = 1\n",
    "\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name).get_dataset_()\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=False)\n",
    "test_dataloader_shuffle = DataLoader(\n",
    "    test_dataset, batch_size=args_config[\"learning\"][\"batch_size\"], shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "178cd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_har_bce = EnsembleCPDModel(args_config, n_models=10)\n",
    "ens_har_bce.load_models_list(\n",
    "    f\"saved_models/{args_config['loss_type']}/{experiments_name}/full_sample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1791fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_head_model = MLPHeadModel(\n",
    "    ens_model=ens_har_bce,\n",
    "    train_dl=train_dataloader,\n",
    "    val_dl=test_dataloader,\n",
    "    num_models=10,\n",
    "    hidden_size=16,\n",
    "    learning_rate=1e-3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de338802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, labels = next(iter(train_dataloader))\n",
    "\n",
    "out = mlp_head_model(batch)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/alex/Desktop/LARSS/CPD/code/UE_for_CPD_6.10/lightning_logs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | head | Sequential | 193   \n",
      "1 | loss | BCELoss    | 0     \n",
      "------------------------------------\n",
      "193       Trainable params\n",
      "0         Non-trainable params\n",
      "193       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9650b37567994897b31bb4c58d53bd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comet_logger = CometLogger(\n",
    "  \n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "  accelerator=\"cpu\",\n",
    "  max_epochs=10,\n",
    "  logger=comet_logger\n",
    ")\n",
    "\n",
    "trainer.fit(mlp_head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e5d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50af78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5afb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
